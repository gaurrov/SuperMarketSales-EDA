# Exploratry-Data-Analysis
Exploratory Data Analysis (EDA) project on supermarket sales dataset using Python 

## ðŸ“Œ Project Overview

This repository contains a comprehensive **Exploratory Data Analysis (EDA)** project developed using **Python** and **Jupyter Notebook**. The project closely follows the analysis performed inside the notebook and documents each step in a structured and reproducible manner.

The main purpose of this project is to **understand the dataset deeply**, identify patterns, clean inconsistencies, visualize relationships, and derive meaningful insights that can support further decision-making or machine learning tasks.

---

## ðŸŽ¯ Problem Statement

Raw data is often incomplete, noisy, and unstructured. Before applying any machine learning or statistical models, it is crucial to explore and understand the data.

This project aims to:

- Examine the dataset structure and features  
- Identify missing values and outliers  
- Analyze feature distributions and relationships  
- Summarize key findings through visualizations and statistics  

---

## ðŸ“‚ Dataset Description

- The dataset consists of multiple numerical and categorical features.
- Each feature represents an important attribute contributing to the overall data behavior.
- The dataset is analyzed for:
  - Data types
  - Missing values
  - Duplicate records
  - Outliers

> âš ï¸ Dataset file may not be included due to licensing or privacy constraints.

---

## ðŸ§ª Steps Performed in the Notebook

### 1ï¸âƒ£ Importing Required Libraries

The following Python libraries are used throughout the analysis:

- **NumPy** for numerical operations  
- **Pandas** for data manipulation  
- **Matplotlib & Seaborn** for visualization  

---

### 2ï¸âƒ£ Data Loading & Initial Inspection

- Loaded the dataset into a Pandas DataFrame  
- Displayed the first few rows to understand data layout  
- Checked dataset shape (rows Ã— columns)  
- Examined column names and data types  

---

### 3ï¸âƒ£ Data Cleaning & Preprocessing

- Identified missing values using `.isnull()`  
- Handled missing data using appropriate strategies (removal / imputation)  
- Checked for duplicate rows  
- Verified data consistency and formatting  

---

### 4ï¸âƒ£ Descriptive Statistical Analysis

- Generated summary statistics using `.describe()`  
- Analyzed:
  - Mean, median, standard deviation  
  - Minimum and maximum values  
  - Distribution spread  

This step helped in understanding the overall behavior of numerical features.

---

### 5ï¸âƒ£ Univariate Analysis

- Studied individual feature distributions  
- Used:
  - Histograms  
  - Box plots  
- Identified skewness and outliers  

---

### 6ï¸âƒ£ Bivariate & Multivariate Analysis

- Analyzed relationships between multiple variables  
- Used:
  - Scatter plots  
  - Correlation heatmaps  
- Observed strong and weak correlations between features  

---

### 7ï¸âƒ£ Data Visualization

- Visualized patterns using clean and interpretable plots  
- Identified trends and anomalies visually  
- Improved interpretability of raw numerical data  

---

### 8ï¸âƒ£ Key Observations & Insights

- Discovered important feature relationships  
- Identified variables with strong influence  
- Detected potential anomalies and unusual patterns  

> All insights are explained in detail inside the notebook.

---

## ðŸ›  Technologies & Tools Used

- **Language:** Python 3.x  
- **IDE:** Jupyter Notebook  
- **Libraries:**
  - NumPy  
  - Pandas  
  - Matplotlib  
  - Seaborn  




